# Fake-Audio-Detection
ABSTRACT

In the modern world, audio morphing is widespread, and detecting such malpractices is foremost important for law enforcement agencies as well as for the protection of any individual's integrity. Advancements in creation of such fake audio clips has overtaken the possible ways of expediting them. We were aiming for a way to detect audio forgery using various machine learning algorithms. Deepfakes are a synthetic means in which a person is replaced with someone else’s affinity. Deepfake audio is created using AI and machine learning algorithms, which is a discrete creation method from the traditional audio manipulation using audio editing software like Lyrebird AI, Overdub etc. Deepfake audio can be used for various purposes, spanning from entertainment to criminal activities. Most deepfake audio apps are meant for entertainment purposes but have the potential to be used for more harmful intents and purposes for wide spreading rumours and for other criminal purposes. This work is an attempt to classify such audio clips as Fake or Authentic. Data set consists of various Narendra Modi speeches from by various rallies all across India from different timelines. Data set is pre-processed using a software called Goldwave which helped us reduce the noise in the samples. Data sets will then be used to train a machine learning models using TensorFlow and Keras. We achieved our goal of classifying the audios successfully with a accuracy rate of 97.69%. The accuracy achieved is so high due to the contraints of the dataset.

Chapter 1. Introduction

Deepfake audio can be used for various purposes, spanning from entertainment to criminal activities. Data set consists of various Narendra Modi speeches from by various rallies all across India from different timelines. We achieved our goal of classifying the audios successfully with an accuracy rate of 97.69%. The accuracy achieved is so high due to the constraints of the dataset. The data set is pre-processed using a software called Goldwave which helped us reduce the noise in the samples. Data sets will then be used to train a machine learning models using TensorFlow and Keras. We hope this will help law enforcement agencies detect such malpractices.

1.1 Introduction to work done/ Motivation

Over the past few years, there’s been an expansion in new research using neural networks to simulate a human voice. These models, mainly developed at tech giants like Google, can generate increasingly realistic, human-like speech. While the progress is overwhelming, we are aware of the risks this technology can pose if used with the immoral intent. It may be used to synthesize speech to fool voice authentication systems, or they might be used to create forged audio recordings to defame public figures and spread rumors. Perhaps equally concerning, public awareness of "deep fakes" (audio or video clips generated by deep learning models) can be exploited to manipulate faith in media: as it becomes harder to differentiate real from tampered content. If we perfect the art of fake audio detection, we can help identify fake audios preventing spreading of rumors and hate speech and make better informed decisions. Future application of such a system can make voice recognition and authentication systems more robust and secure.

1.2 Project Statement / Objectives of the Project

The inaccuracy with which we can today deal with audio deep fakes and misconception & rumors in the society through social media which could have been prevented, had there been such systems in place. The aim is to devise such a system to avoid the mentioned situations. Our project’s main aim is to predict, with accuracy, the speech features of various public figures like PM Narendra Modi using signal processing algorithms. Then further apply neural network to classify them as a Fake or Real Audio.

Chapter 2. Background Overview

2.1  Conceptual Overview (Concepts/ Theory used)

CNN is one of the most common types of neural networks used to recognize and classify pictures. CNNs are commonly utilized in domains such as object detection, face recognition, and so on. CNN image classifications takes an input image, processes it, and categorizes it into several groups. An input image is seen by computers as an array of pixels, with the number of pixels varying depending on the image resolution.

From the time domain, audio splits are translated to the frequency domain. The amplitude spectrum is the result of this process. The MFCC feature is one of the most essential methods for extracting a feature from an audio signal, and it is frequently utilized when working with audio signals. A signal's mel frequency cepstral coefficients (MFCCs) are a short group of characteristics (often 10–20) that succinctly define the overall shape of a spectral envelope.

                                                            C(x(t)) = F -1[log(F(x(t))]
x(t): Time domain Signal
F -1[log(F(x(t))]: Cepstrum i.e. the result of computing the inverse Fourier transform (IFT) of the logarithm of the estimated signal spectrum.
